{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "1hfG3EM0lZj0",
        "outputId": "ffd25d38-a6fb-460f-f3dc-d74787d1b2e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-415fad6af2c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# Define data directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Attention Modules ---\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        y = torch.cat([avg_out, max_out], dim=1)\n",
        "        y = self.conv1(y)\n",
        "        return self.sigmoid(y) * x\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out) * x\n",
        "\n",
        "# --- Multi-Scale Feature Extractor ---\n",
        "class DilatedConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dilation_rate):\n",
        "        super(DilatedConvLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation_rate, dilation=dilation_rate)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv(x))\n",
        "\n",
        "class PyramidPoolingLayer(nn.Module):\n",
        "    def __init__(self, in_channels, pool_sizes=(1, 2, 3, 6)):\n",
        "        super(PyramidPoolingLayer, self).__init__()\n",
        "        self.pools = nn.ModuleList()\n",
        "        for size in pool_sizes:\n",
        "            self.pools.append(nn.AdaptiveAvgPool2d(size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        pooled_outputs = [x]\n",
        "        for pool in self.pools:\n",
        "            pooled = pool(x)\n",
        "            pooled = F.interpolate(pooled, size=(height, width), mode='bilinear', align_corners=False)\n",
        "            pooled_outputs.append(pooled)\n",
        "        output = torch.cat(pooled_outputs, dim=1)\n",
        "        return output\n",
        "\n",
        "class MultiScaleFeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(MultiScaleFeatureExtractor, self).__init__()\n",
        "        dcl_out_channels = 64\n",
        "        ppl_out_mult = len(PyramidPoolingLayer(1).pools) + 1\n",
        "\n",
        "        # Branch 1 (processes original)\n",
        "        self.dcl1 = DilatedConvLayer(1, dcl_out_channels, dilation_rate=1)\n",
        "        self.sa1 = SpatialAttention()\n",
        "        self.ca1 = ChannelAttention(dcl_out_channels)\n",
        "        self.ppl1 = PyramidPoolingLayer(dcl_out_channels)\n",
        "        self.conv1_1 = nn.Conv2d(dcl_out_channels * ppl_out_mult, dcl_out_channels, kernel_size=1)\n",
        "\n",
        "        # Branch 2 (processes original)\n",
        "        self.dcl2 = DilatedConvLayer(1, dcl_out_channels, dilation_rate=2)\n",
        "        self.sa2 = SpatialAttention()\n",
        "        self.ca2 = ChannelAttention(dcl_out_channels)\n",
        "        self.ppl2 = PyramidPoolingLayer(dcl_out_channels)\n",
        "        self.conv2_1 = nn.Conv2d(dcl_out_channels * ppl_out_mult, dcl_out_channels, kernel_size=1)\n",
        "\n",
        "        # Branch 3 (processes noisy)\n",
        "        dcl4_out_channels = dcl_out_channels // 2\n",
        "        dcl8_out_channels = dcl_out_channels // 2\n",
        "        self.dcl4 = DilatedConvLayer(1, dcl4_out_channels, dilation_rate=4)\n",
        "        self.dcl8 = DilatedConvLayer(1, dcl8_out_channels, dilation_rate=8)\n",
        "        self.sa3 = SpatialAttention()\n",
        "        self.ca3 = ChannelAttention(dcl4_out_channels + dcl8_out_channels)\n",
        "        self.ppl3 = PyramidPoolingLayer(dcl4_out_channels + dcl8_out_channels)\n",
        "        self.conv3_1 = nn.Conv2d((dcl4_out_channels + dcl8_out_channels) * ppl_out_mult, dcl_out_channels, kernel_size=1)\n",
        "\n",
        "        # Final Fusion\n",
        "        self.final_conv = nn.Conv2d(dcl_out_channels * 3, 256, kernel_size=1)\n",
        "\n",
        "    def forward(self, combined_input):\n",
        "        original_img = combined_input[:, 0:1, :, :]\n",
        "        noisy_img = combined_input[:, 1:2, :, :]\n",
        "\n",
        "        fe1 = self.dcl1(original_img)\n",
        "        attn1 = self.sa1(fe1) + self.ca1(fe1)\n",
        "        ppl1_out = self.ppl1(attn1)\n",
        "        f1 = self.conv1_1(ppl1_out)\n",
        "\n",
        "        fe2 = self.dcl2(original_img)\n",
        "        attn2 = self.sa2(fe2) + self.ca2(fe2)\n",
        "        ppl2_out = self.ppl2(attn2)\n",
        "        f2 = self.conv2_1(ppl2_out)\n",
        "\n",
        "        fe4 = self.dcl4(noisy_img)\n",
        "        fe8 = self.dcl8(noisy_img)\n",
        "        fe_concat = torch.cat([fe4, fe8], dim=1)\n",
        "        attn3 = self.sa3(fe_concat) + self.ca3(fe_concat)\n",
        "        ppl3_out = self.ppl3(attn3)\n",
        "        f3 = self.conv3_1(ppl3_out)\n",
        "\n",
        "        self.intermediate_features = torch.cat([f1, f2, f3], dim=1)\n",
        "        final_features = self.final_conv(self.intermediate_features)\n",
        "        return final_features\n",
        "\n",
        "# --- UNet for Denoising ---\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class DenoisingUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, feature_channels):\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels + feature_channels # Input noisy + extracted features\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.inc = DoubleConv(self.n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024 // 2)\n",
        "        self.up1 = Up(1024 // 2 + 512, 512)\n",
        "        self.up2 = Up(512 + 256, 256)\n",
        "        self.up3 = Up(256 + 128, 128)\n",
        "        self.up4 = Up(128 + 64, 64)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, noisy_input, features):\n",
        "        x = torch.cat([noisy_input, features], dim=1)\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "# --- Dataset Class ---\n",
        "class UltrasoundDataset(Dataset):\n",
        "    def __init__(self, original_dir, noisy_dir, transform=None):\n",
        "        self.original_dir = original_dir\n",
        "        self.noisy_dir = noisy_dir\n",
        "        self.transform = transform\n",
        "        self.original_files = sorted([f for f in os.listdir(original_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "        self.noisy_files = sorted([f for f in os.listdir(noisy_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "\n",
        "        if len(self.original_files) != len(self.noisy_files):\n",
        "            raise ValueError(f\"Number of original and noisy images does not match in: {original_dir} vs {noisy_dir}\")\n",
        "\n",
        "        self.pairs = []\n",
        "        for i in range(len(self.original_files)):\n",
        "            original_path = os.path.join(original_dir, self.original_files[i])\n",
        "            noisy_path = os.path.join(noisy_dir, self.noisy_files[i])\n",
        "            self.pairs.append((original_path, noisy_path))\n",
        "\n",
        "        print(f\"Found {len(self.pairs)} images in: {original_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_path, noisy_path = self.pairs[idx]\n",
        "        original_img = Image.open(original_path).convert('L')\n",
        "        noisy_img = Image.open(noisy_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            original_img = self.transform(original_img)\n",
        "            noisy_img = self.transform(noisy_img)\n",
        "\n",
        "        return noisy_img, original_img\n",
        "\n",
        "def calculate_epi(denoised, original):\n",
        "    # Placeholder for EPI calculation. Implement the actual formula if you have it.\n",
        "    return 0\n",
        "\n",
        "def train_model(model, feature_extractor, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n",
        "    feature_extractor.eval() # Keep feature extractor frozen during UNet training\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for noisy_batch, clean_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\"):\n",
        "            noisy_batch = noisy_batch.to(device)\n",
        "            clean_batch = clean_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                combined_batch = torch.cat([clean_batch, noisy_batch], dim=1)\n",
        "                features_batch = feature_extractor(combined_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            denoised_batch = model(noisy_batch, features_batch)\n",
        "            loss = criterion(denoised_batch, clean_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * noisy_batch.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_psnr = []\n",
        "        val_ssim = []\n",
        "        with torch.no_grad():\n",
        "            for noisy_batch, clean_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Val)\"):\n",
        "                noisy_batch = noisy_batch.to(device)\n",
        "                clean_batch = clean_batch.to(device)\n",
        "                combined_batch = torch.cat([clean_batch, noisy_batch], dim=1)\n",
        "                features_batch = feature_extractor(combined_batch)\n",
        "                denoised_batch = model(noisy_batch, features_batch)\n",
        "                loss = criterion(denoised_batch, clean_batch)\n",
        "                val_loss += loss.item() * noisy_batch.size(0)\n",
        "\n",
        "                denoised_np = denoised_batch.squeeze().cpu().numpy()\n",
        "                clean_np = clean_batch.squeeze().cpu().numpy()\n",
        "                for i in range(denoised_np.shape[0]): # Iterate over batch\n",
        "                    psnr = peak_signal_noise_ratio(clean_np[i], denoised_np[i], data_range=1.0)\n",
        "                    ssim = structural_similarity(clean_np[i], denoised_np[i], data_range=1.0)\n",
        "                    val_psnr.append(psnr)\n",
        "                    val_ssim.append(ssim)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        avg_val_psnr = np.mean(val_psnr)\n",
        "        avg_val_ssim = np.mean(val_ssim)\n",
        "        print(f\"Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val PSNR: {avg_val_psnr:.4f} dB, Val SSIM: {avg_val_ssim:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def test_model(model, feature_extractor,test_loader, device):\n",
        "    model.eval()\n",
        "    test_psnr = []\n",
        "    test_ssim = []\n",
        "    test_epi = []\n",
        "    with torch.no_grad():\n",
        "        for noisy_batch, clean_batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            noisy_batch = noisy_batch.to(device)\n",
        "            clean_batch = clean_batch.to(device)\n",
        "            combined_batch = torch.cat([clean_batch, noisy_batch], dim=1)\n",
        "            features_batch = feature_extractor(combined_batch)\n",
        "            denoised_batch = model(noisy_batch, features_batch)\n",
        "\n",
        "            denoised_np = denoised_batch.squeeze().cpu().numpy()\n",
        "            clean_np = clean_batch.squeeze().cpu().numpy()\n",
        "\n",
        "            for i in range(denoised_np.shape[0]):\n",
        "                psnr = peak_signal_noise_ratio(clean_np[i], denoised_np[i], data_range=1.0)\n",
        "                ssim = structural_similarity(clean_np[i], denoised_np[i], data_range=1.0)\n",
        "                epi = calculate_epi(denoised_np[i], clean_np[i]) # Calculate EPI\n",
        "                test_psnr.append(psnr)\n",
        "                test_ssim.append(ssim)\n",
        "                test_epi.append(epi)\n",
        "\n",
        "    avg_test_psnr = np.mean(test_psnr)\n",
        "    avg_test_ssim = np.mean(test_ssim)\n",
        "    avg_test_epi = np.mean(test_epi)\n",
        "    print(f\"Test PSNR: {avg_test_psnr:.4f} dB, Test SSIM: {avg_test_ssim:.4f}, Test EPI: {avg_test_epi:.4f}\")\n",
        "    return avg_test_psnr, avg_test_ssim, avg_test_epi\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define data directories\n",
        "    train_original_dir = '/content/drive/MyDrive/US_Speckle_dir/train_original_US' # Replace with your paths\n",
        "    train_noisy_dir = '/content/drive/MyDrive/US_Speckle_dir/train_noisy_US'\n",
        "    val_original_dir = '/content/drive/MyDrive/US_Speckle_dir/val_original_US'\n",
        "    val_noisy_dir = '/content/drive/MyDrive/US_Speckle_dir/val_noisy_US'\n",
        "    test_original_dir = '/content/drive/MyDrive/US_Speckle_dir/test_original_US'\n",
        "    test_noisy_dir = '/content/drive/MyDrive/US_Speckle_dir/test_noisy_US'\n",
        "\n",
        "    # Hyperparameters\n",
        "    batch_size = 4\n",
        "    learning_rate = 0.001\n",
        "    num_epochs = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Create Datasets\n",
        "    train_dataset = UltrasoundDataset(train_original_dir, train_noisy_dir, transform=transform)\n",
        "    val_dataset = UltrasoundDataset(val_original_dir, val_noisy_dir, transform=transform)\n",
        "    test_dataset = UltrasoundDataset(test_original_dir, test_noisy_dir, transform=transform)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1) # Typically batch size 1 for testing/evaluation\n",
        "\n",
        "    # Initialize Feature Extractor and UNet\n",
        "    feature_extractor = MultiScaleFeatureExtractor(2).to(device)\n",
        "    feature_channels = 256 # Output channels of the feature extractor's final conv\n",
        "    unet_model = DenoisingUNet(n_channels=1, n_classes=1, feature_channels=feature_channels).to(device)\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(unet_model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the model\n",
        "    trained_unet = train_model(unet_model, feature_extractor, train_loader, val_loader, optimizer, criterion, num_epochs, device)\n",
        "\n",
        "    # Test the model\n",
        "    avg_test_psnr, avg_test_ssim, avg_test_epi = test_model(trained_unet, feature_extractor, test_loader, device)\n",
        "    print(f\"Average Test PSNR: {avg_test_psnr:.4f} dB\")\n",
        "    print(f\"Average Test SSIM: {avg_test_ssim:.4f}\")\n",
        "    print(f\"Average Test EPI: {avg_test_epi:.4f}\")\n",
        "\n",
        "    # You can add code here to visualize test results if needed"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gS_Y5Zv-mLh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}